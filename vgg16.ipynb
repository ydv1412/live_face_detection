{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vgg16.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1gy0nqMwv073OdUOl2iKFidXnr3ZwXXnk",
      "authorship_tag": "ABX9TyPXkFIhWqEoVs3vxCUGozNr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ydv1412/live_face_detection/blob/main/vgg16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dOK-7QIEO0Qi"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import keras\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.preprocessing.image import load_img\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = ImageDataGenerator(rescale = 1/255.0) \n",
        "\n",
        "test_generator = ImageDataGenerator(rescale = 1/255.0 , validation_split = 0.5) "
      ],
      "metadata": {
        "id": "urDMlISuPCDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_Data = train_generator.flow_from_directory('//content//drive//MyDrive//capstone project //computer vision_face_emotion_recognisation//dataset//train' ,target_size = (224,224), batch_size= 128 , class_mode = 'binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVUr_GxfPHgH",
        "outputId": "e95df386-c944-43b7-b5d8-1098b50ce96f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10420 images belonging to 7 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_Data = test_generator.flow_from_directory('/content/drive/MyDrive/capstone project /computer vision_face_emotion_recognisation/dataset/test' ,target_size = (224,224), batch_size= 128 , class_mode = 'binary' , subset = 'validation')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tr0kMFPtPLSj",
        "outputId": "90cc1637-95a6-4f59-cb1f-65c903b8e810"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3587 images belonging to 7 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_Data = test_generator.flow_from_directory('/content/drive/MyDrive/capstone project /computer vision_face_emotion_recognisation/dataset/test' ,target_size = (224,224), batch_size= 128 , class_mode = 'binary',subset = 'training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXR38CufP176",
        "outputId": "51d1f596-0e8f-4692-97b4-4bef083d9708"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3591 images belonging to 7 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = VGG16(input_shape = (224,224,3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FStSGvVyP5f3",
        "outputId": "f1156892-531a-4f51-a378-7e49d3fc5a05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 5s 0us/step\n",
            "553476096/553467096 [==============================] - 5s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZWzmKlbQkzS",
        "outputId": "3cbfe912-3d93-475c-8bf4-c95d595f0177"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 4096)              102764544 \n",
            "                                                                 \n",
            " fc2 (Dense)                 (None, 4096)              16781312  \n",
            "                                                                 \n",
            " predictions (Dense)         (None, 1000)              4097000   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_input = base_model.layers[0].input\n",
        "base_output = base_model.layers[-2].output"
      ],
      "metadata": {
        "id": "eoud9OrQP-kQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Model( inputs = base_input , outputs = base_output)"
      ],
      "metadata": {
        "id": "dBUlNGNTQNy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.trainable = False"
      ],
      "metadata": {
        "id": "u3zPc5wLRuXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = model.output\n",
        "final_model = keras.layers.Dense(128 , activation = 'relu')(x)\n",
        "final_model = keras.layers.Dropout(0.5)\n",
        "final_model = keras.layers.Dense(64 , activation = 'relu')(final_model)\n",
        "final_model = keras.layers.Dropout(0.5)\n",
        "final_model = keras.layers.Denses(32 , activation = 'relu')(final_model)\n",
        "final_model = keras.layers.Dropout(0.5)\n",
        "final_model = keras.layers.Dense(7 , activation = 'softmax')(final_model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "pkY-Dl71RwI3",
        "outputId": "0a48a4a0-8642-4e89-ab69-dffb74b16eaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-75fc63f46417>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfinal_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfinal_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfinal_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mfinal_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mfinal_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDenses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# have a `shape` attribute.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Inputs to a layer should be tensors. Got: {x}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Inputs to a layer should be tensors. Got: <keras.layers.core.dropout.Dropout object at 0x7fed180e1650>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dDUn-8DgSMiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaEIovIKT9CZ",
        "outputId": "64846b20-a336-4654-ad97-7db06a97b3b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n",
            "58900480/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in vgg_model.layers[:15]:\n",
        "    layer.trainable = False\n",
        "# Make sure you have frozen the correct layers\n",
        "for i, layer in enumerate(vgg_model.layers):\n",
        "    print(i, layer.name, layer.trainable)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6U8rCp3USIQ",
        "outputId": "1f01dd1c-cc26-4859-b2c1-84cf9557ca4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 input_2 False\n",
            "1 block1_conv1 False\n",
            "2 block1_conv2 False\n",
            "3 block1_pool False\n",
            "4 block2_conv1 False\n",
            "5 block2_conv2 False\n",
            "6 block2_pool False\n",
            "7 block3_conv1 False\n",
            "8 block3_conv2 False\n",
            "9 block3_conv3 False\n",
            "10 block3_pool False\n",
            "11 block4_conv1 False\n",
            "12 block4_conv2 False\n",
            "13 block4_conv3 False\n",
            "14 block4_pool False\n",
            "15 block5_conv1 True\n",
            "16 block5_conv2 True\n",
            "17 block5_conv3 True\n",
            "18 block5_pool True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = vgg_model.output\n",
        "x = keras.layers.Flatten()(x) # Flatten dimensions to for use in FC layers\n",
        "x = keras.layers.Dense(512, activation='relu')(x)\n",
        "x = keras.layers.Dropout(0.5)(x) # Dropout layer to reduce overfitting\n",
        "x = keras.layers.Dense(256, activation='relu')(x)\n",
        "x = keras.layers.Dense(8, activation='softmax')(x) # Softmax for multiclass\n",
        "transfer_model = keras.Model(inputs=vgg_model.input, outputs=x)"
      ],
      "metadata": {
        "id": "J8X5WVwcUUZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transfer_model.compile(loss = 'sparse_categorical_crossentropy' , optimizer = 'adam' , metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "g2nqs6yGVhf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transfer_model.fit(train_Data, epochs=25, validation_data=validation_Data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9OwZXuoVrGG",
        "outputId": "3d481701-c87c-4dd3-c5f7-18e50cb3a961"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "82/82 [==============================] - 3256s 40s/step - loss: 1.3378 - accuracy: 0.3748 - val_loss: 3.9122 - val_accuracy: 0.1427\n",
            "Epoch 2/25\n",
            "82/82 [==============================] - 123s 2s/step - loss: 1.1911 - accuracy: 0.3924 - val_loss: 4.8079 - val_accuracy: 0.1399\n",
            "Epoch 3/25\n",
            "82/82 [==============================] - 123s 2s/step - loss: 1.1839 - accuracy: 0.3866 - val_loss: 4.3242 - val_accuracy: 0.1408\n",
            "Epoch 4/25\n",
            "82/82 [==============================] - 123s 1s/step - loss: 1.1451 - accuracy: 0.4119 - val_loss: 5.8752 - val_accuracy: 0.2975\n",
            "Epoch 5/25\n",
            "82/82 [==============================] - 123s 1s/step - loss: 0.9661 - accuracy: 0.5546 - val_loss: 6.9036 - val_accuracy: 0.3195\n",
            "Epoch 6/25\n",
            "82/82 [==============================] - 123s 1s/step - loss: 0.8642 - accuracy: 0.6153 - val_loss: 7.3522 - val_accuracy: 0.3306\n",
            "Epoch 7/25\n",
            "82/82 [==============================] - 123s 1s/step - loss: 0.7860 - accuracy: 0.6616 - val_loss: 7.0507 - val_accuracy: 0.3354\n",
            "Epoch 8/25\n",
            "82/82 [==============================] - 123s 1s/step - loss: 0.7296 - accuracy: 0.6905 - val_loss: 6.2959 - val_accuracy: 0.3613\n",
            "Epoch 9/25\n",
            "82/82 [==============================] - 135s 2s/step - loss: 0.6438 - accuracy: 0.7299 - val_loss: 7.1655 - val_accuracy: 0.3794\n",
            "Epoch 10/25\n",
            "82/82 [==============================] - 123s 1s/step - loss: 0.5704 - accuracy: 0.7666 - val_loss: 7.8724 - val_accuracy: 0.3607\n",
            "Epoch 11/25\n",
            "82/82 [==============================] - 123s 1s/step - loss: 0.5026 - accuracy: 0.7982 - val_loss: 6.9314 - val_accuracy: 0.3711\n",
            "Epoch 12/25\n",
            "82/82 [==============================] - 123s 1s/step - loss: 0.4278 - accuracy: 0.8286 - val_loss: 8.7050 - val_accuracy: 0.3719\n",
            "Epoch 13/25\n",
            "82/82 [==============================] - 123s 1s/step - loss: 0.3569 - accuracy: 0.8621 - val_loss: 8.1091 - val_accuracy: 0.3758\n",
            "Epoch 14/25\n",
            "82/82 [==============================] - 123s 2s/step - loss: 0.3193 - accuracy: 0.8774 - val_loss: 10.1792 - val_accuracy: 0.3733\n",
            "Epoch 15/25\n",
            "82/82 [==============================] - 123s 2s/step - loss: 0.2577 - accuracy: 0.9057 - val_loss: 11.9387 - val_accuracy: 0.3560\n",
            "Epoch 16/25\n",
            "82/82 [==============================] - 123s 2s/step - loss: 0.2192 - accuracy: 0.9160 - val_loss: 11.6375 - val_accuracy: 0.3476\n",
            "Epoch 17/25\n",
            "82/82 [==============================] - 123s 2s/step - loss: 0.1721 - accuracy: 0.9383 - val_loss: 12.9117 - val_accuracy: 0.3705\n",
            "Epoch 18/25\n",
            "82/82 [==============================] - 123s 2s/step - loss: 0.1544 - accuracy: 0.9434 - val_loss: 12.3752 - val_accuracy: 0.3783\n",
            "Epoch 19/25\n",
            "82/82 [==============================] - 123s 2s/step - loss: 0.1325 - accuracy: 0.9488 - val_loss: 13.4990 - val_accuracy: 0.3817\n",
            "Epoch 20/25\n",
            "82/82 [==============================] - 123s 2s/step - loss: 0.1179 - accuracy: 0.9574 - val_loss: 13.8629 - val_accuracy: 0.3543\n",
            "Epoch 21/25\n",
            "82/82 [==============================] - 123s 2s/step - loss: 0.1061 - accuracy: 0.9638 - val_loss: 14.0037 - val_accuracy: 0.3605\n",
            "Epoch 22/25\n",
            "82/82 [==============================] - 123s 2s/step - loss: 0.0855 - accuracy: 0.9714 - val_loss: 13.2016 - val_accuracy: 0.3610\n",
            "Epoch 23/25\n",
            "82/82 [==============================] - 123s 2s/step - loss: 0.0561 - accuracy: 0.9817 - val_loss: 19.1881 - val_accuracy: 0.3691\n",
            "Epoch 24/25\n",
            "82/82 [==============================] - 123s 2s/step - loss: 0.0808 - accuracy: 0.9731 - val_loss: 15.2014 - val_accuracy: 0.3655\n",
            "Epoch 25/25\n",
            "82/82 [==============================] - 123s 2s/step - loss: 0.0796 - accuracy: 0.9731 - val_loss: 15.2124 - val_accuracy: 0.3716\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fed17c30e50>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2ECnufRnV1j9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg_model2 = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "x1 = vgg_model2.output\n",
        "x1 = keras.layers.Flatten()(x1) # Flatten dimensions to for use in FC layers\n",
        "x1 = keras.layers.Dense(512, activation='relu')(x1)\n",
        "x1 = keras.layers.Dropout(0.5)(x1) # Dropout layer to reduce overfitting\n",
        "x1 = keras.layers.Dense(256, activation='relu')(x1)\n",
        "x1 = keras.layers.Dense(7, activation='softmax')(x1) # Softmax for multiclass\n",
        "transfer_model2 = keras.Model(inputs=vgg_model2.input, outputs=x1)\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
        "transfer_model2.compile(loss = 'sparse_categorical_crossentropy' , optimizer = opt , metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "sJHo0pPVsdA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = transfer_model2.fit(train_Data, epochs=25, validation_data=validation_Data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_obL414nul5a",
        "outputId": "a9ce92b2-df01-4d99-d6af-4508c865b2c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "82/82 [==============================] - 1989s 24s/step - loss: 1.2580 - accuracy: 0.3939 - val_loss: 3.6118 - val_accuracy: 0.1915\n",
            "Epoch 2/25\n",
            "82/82 [==============================] - 335s 4s/step - loss: 0.9915 - accuracy: 0.5490 - val_loss: 4.1372 - val_accuracy: 0.3298\n",
            "Epoch 3/25\n",
            "82/82 [==============================] - 335s 4s/step - loss: 0.8296 - accuracy: 0.6459 - val_loss: 4.1035 - val_accuracy: 0.3872\n",
            "Epoch 4/25\n",
            "82/82 [==============================] - 335s 4s/step - loss: 0.7273 - accuracy: 0.6951 - val_loss: 4.0476 - val_accuracy: 0.4001\n",
            "Epoch 5/25\n",
            "82/82 [==============================] - 335s 4s/step - loss: 0.6586 - accuracy: 0.7295 - val_loss: 4.1506 - val_accuracy: 0.4003\n",
            "Epoch 6/25\n",
            "82/82 [==============================] - 335s 4s/step - loss: 0.6022 - accuracy: 0.7583 - val_loss: 4.4438 - val_accuracy: 0.3995\n",
            "Epoch 7/25\n",
            "82/82 [==============================] - 335s 4s/step - loss: 0.5153 - accuracy: 0.7937 - val_loss: 4.5638 - val_accuracy: 0.4090\n",
            "Epoch 8/25\n",
            "82/82 [==============================] - 336s 4s/step - loss: 0.4236 - accuracy: 0.8343 - val_loss: 4.7454 - val_accuracy: 0.4051\n",
            "Epoch 9/25\n",
            "82/82 [==============================] - 336s 4s/step - loss: 0.3524 - accuracy: 0.8598 - val_loss: 5.1147 - val_accuracy: 0.4118\n",
            "Epoch 10/25\n",
            "82/82 [==============================] - 336s 4s/step - loss: 0.2647 - accuracy: 0.8968 - val_loss: 5.9551 - val_accuracy: 0.4137\n",
            "Epoch 11/25\n",
            "82/82 [==============================] - 336s 4s/step - loss: 0.1851 - accuracy: 0.9297 - val_loss: 6.3335 - val_accuracy: 0.4159\n",
            "Epoch 12/25\n",
            "82/82 [==============================] - 335s 4s/step - loss: 0.1674 - accuracy: 0.9392 - val_loss: 6.3556 - val_accuracy: 0.4162\n",
            "Epoch 13/25\n",
            "82/82 [==============================] - 336s 4s/step - loss: 0.1150 - accuracy: 0.9605 - val_loss: 6.5564 - val_accuracy: 0.4157\n",
            "Epoch 14/25\n",
            "82/82 [==============================] - 336s 4s/step - loss: 0.0756 - accuracy: 0.9742 - val_loss: 8.4764 - val_accuracy: 0.4165\n",
            "Epoch 15/25\n",
            "82/82 [==============================] - 336s 4s/step - loss: 0.0762 - accuracy: 0.9738 - val_loss: 7.1545 - val_accuracy: 0.4140\n",
            "Epoch 16/25\n",
            "82/82 [==============================] - 335s 4s/step - loss: 0.0576 - accuracy: 0.9812 - val_loss: 8.0163 - val_accuracy: 0.4104\n",
            "Epoch 17/25\n",
            "82/82 [==============================] - 336s 4s/step - loss: 0.0557 - accuracy: 0.9819 - val_loss: 8.0717 - val_accuracy: 0.3984\n",
            "Epoch 18/25\n",
            "82/82 [==============================] - 336s 4s/step - loss: 0.0565 - accuracy: 0.9807 - val_loss: 8.4644 - val_accuracy: 0.4034\n",
            "Epoch 19/25\n",
            "82/82 [==============================] - 335s 4s/step - loss: 0.0503 - accuracy: 0.9837 - val_loss: 8.0325 - val_accuracy: 0.4109\n",
            "Epoch 20/25\n",
            "82/82 [==============================] - 335s 4s/step - loss: 0.0256 - accuracy: 0.9917 - val_loss: 10.5144 - val_accuracy: 0.4093\n",
            "Epoch 21/25\n",
            "82/82 [==============================] - 335s 4s/step - loss: 0.0297 - accuracy: 0.9927 - val_loss: 8.0738 - val_accuracy: 0.4095\n",
            "Epoch 22/25\n",
            "82/82 [==============================] - 335s 4s/step - loss: 0.0294 - accuracy: 0.9898 - val_loss: 8.9456 - val_accuracy: 0.4051\n",
            "Epoch 23/25\n",
            "82/82 [==============================] - 335s 4s/step - loss: 0.0449 - accuracy: 0.9855 - val_loss: 7.6153 - val_accuracy: 0.4198\n",
            "Epoch 24/25\n",
            "82/82 [==============================] - 335s 4s/step - loss: 0.0359 - accuracy: 0.9873 - val_loss: 7.8400 - val_accuracy: 0.4115\n",
            "Epoch 25/25\n",
            "82/82 [==============================] - 335s 4s/step - loss: 0.0250 - accuracy: 0.9922 - val_loss: 9.7561 - val_accuracy: 0.4154\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transfer_model2.save_weights('/content/drive/MyDrive/capstone project /computer vision_face_emotion_recognisation/vgg_trainable.h5')"
      ],
      "metadata": {
        "id": "W56Oi_YIur5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Ejbog1yrCHfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg_model2 = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "x2 = vgg_model2.output\n",
        "x2 = keras.layers.Flatten()(x2)\n",
        "x2 = keras.layers.Dense(7, activation='softmax')(x2) # Softmax for multiclass\n",
        "transfer_model3 = keras.Model(inputs=vgg_model2.input, outputs=x2)\n",
        "transfer_model3.compile(loss = 'sparse_categorical_crossentropy' , optimizer = 'adam' , metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "GsclIx_eA-ZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history2 = transfer_model3.fit(train_Data, epochs=25, validation_data=validation_Data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jMIJjRCKBHXy",
        "outputId": "15d47559-fbf9-4dd3-92d1-97f9c068c856"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-e99901a2e34f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransfer_model3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_Data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_Data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n    File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n      handler_func(fileobj, events)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 452, in _handle_events\n      self._handle_recv()\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 481, in _handle_recv\n      self._run_callback(callback, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 431, in _run_callback\n      callback(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n      return self.dispatch_shell(stream, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n      handler(stream, idents, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n      user_expressions, allow_stdin)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n      if self.run_code(code, result):\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-11-e99901a2e34f>\", line 1, in <module>\n      history2 = transfer_model3.fit(train_Data, epochs=25, validation_data=validation_Data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 860, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 919, in compute_loss\n      y, y_pred, sample_weight, regularization_losses=self.losses)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 201, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 141, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 245, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 1863, in sparse_categorical_crossentropy\n      y_true, y_pred, from_logits=from_logits, axis=axis)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/backend.py\", line 5203, in sparse_categorical_crossentropy\n      labels=target, logits=output)\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\nlogits and labels must have the same first dimension, got logits shape [6272,7] and labels shape [128]\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_2966]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DWEEYEC5BRYJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}